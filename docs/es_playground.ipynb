{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "920a3c1a",
   "metadata": {},
   "source": [
    "# Elasticsearch langchain playground\n",
    "\n",
    "First, let's configure connection to our Elasticsearch cluster in cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f186c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"LANGCHAIN_HANDLER\"] = \"langchain\"\n",
    "#os.environ[\"LANGCHAIN_TRACING\"] = \"true\"\n",
    "#os.environ[\"LANGCHAIN_SESSION\"] = \"my_session\" # Make sure this session actually exists. You can create a new session in the UI.\n",
    "\n",
    "from langchain import OpenAI, ESEngine, ESChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "ES_URL = os.environ.get(\"ES_URL\", \"https://test1.es.europe-north1.gcp.elastic-cloud.com:443\")\n",
    "KB_URL = os.environ.get(\"KB_URL\", \"https://test1.kb.europe-north1.gcp.elastic-cloud.com:9243\")\n",
    "\n",
    "username = \"elastic\"\n",
    "password = os.environ.get(\"ES_PASSWORD\", \"\")\n",
    "\n",
    "db = ESEngine.from_uri(ES_URL, \n",
    "                       connection_args={\n",
    "                           \"basic_auth\": (username, password),\n",
    "                           \"http_compress\": True,\n",
    "                       },\n",
    "                       sample_docs_in_index_info = 0,\n",
    "                       )\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce11d69f",
   "metadata": {},
   "source": [
    "Let's setup Elasticsearch toolkit to interact with the cluster from langchain agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c8f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import create_elasticsearch_agent\n",
    "from langchain.agents.agent_toolkits import ElasticsearchDatastoreToolkit\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.es_engine import ESEngine\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "#llm = OpenAI(temperature=0, verbose=True)    # use gpt3 model\n",
    "llm = ChatOpenAI(temperature=0, verbose=True) # use gpt-3.5-turbo model\n",
    "toolkit = ElasticsearchDatastoreToolkit(db=db, llm=llm)\n",
    "\n",
    "agent_executor = create_elasticsearch_agent(\n",
    "    llm=llm,\n",
    "    toolkit=toolkit,\n",
    "    top_k=0,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e44ee67",
   "metadata": {},
   "source": [
    "A list of sample questions around data stored in the cluster.\n",
    "We use sample dataset from Kibana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f27fcc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction:\n",
      "```\n",
      "{\n",
      "  \"action\": \"list_indices_es_db\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m.fleet-files-agent-000001, kibana_sample_data_ecommerce, test-123, kibana_sample_data_logs, .fleet-file-data-agent-000001, kibana_sample_data_flights\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should use the `kibana_sample_data_ecommerce` index to answer this question. I need to check the schema of this index to see what fields are available for me to use in the query.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"schema_es_db\",\n",
      "  \"action_input\": \"kibana_sample_data_ecommerce\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIndex: kibana_sample_data_ecommerce\n",
      "Fields: {'category': 'text', 'category.keyword': 'keyword', 'currency': 'keyword', 'customer_birth_date': 'date', 'customer_first_name': 'text', 'customer_first_name.keyword': 'keyword', 'customer_full_name': 'text', 'customer_full_name.keyword': 'keyword', 'customer_gender': 'keyword', 'customer_id': 'keyword', 'customer_last_name': 'text', 'customer_last_name.keyword': 'keyword', 'customer_phone': 'keyword', 'day_of_week': 'keyword', 'day_of_week_i': 'integer', 'email': 'keyword', 'event.dataset': 'keyword', 'geoip.city_name': 'keyword', 'geoip.continent_name': 'keyword', 'geoip.country_iso_code': 'keyword', 'geoip.location': 'geo_point', 'geoip.region_name': 'keyword', 'manufacturer': 'text', 'manufacturer.keyword': 'keyword', 'order_date': 'date', 'order_id': 'keyword', 'products._id': 'text', 'products._id.keyword': 'keyword', 'products.base_price': 'half_float', 'products.base_unit_price': 'half_float', 'products.category': 'text', 'products.category.keyword': 'keyword', 'products.created_on': 'date', 'products.discount_amount': 'half_float', 'products.discount_percentage': 'half_float', 'products.manufacturer': 'text', 'products.manufacturer.keyword': 'keyword', 'products.min_price': 'half_float', 'products.price': 'half_float', 'products.product_id': 'long', 'products.product_name': 'text', 'products.product_name.keyword': 'keyword', 'products.quantity': 'integer', 'products.sku': 'keyword', 'products.tax_amount': 'half_float', 'products.taxful_price': 'half_float', 'products.taxless_price': 'half_float', 'products.unit_discount_amount': 'half_float', 'sku': 'keyword', 'taxful_total_price': 'half_float', 'taxless_total_price': 'half_float', 'total_quantity': 'integer', 'total_unique_products': 'integer', 'type': 'keyword', 'user': 'keyword'}\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI can use the `order_date` field to filter by date and the `taxful_total_price` field to calculate the daily spending. I will use a date histogram aggregation to group the results by day. \n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"query_es_db\",\n",
      "  \"action_input\": {\n",
      "    \"index_name\": \"kibana_sample_data_ecommerce\",\n",
      "    \"query\": {\n",
      "      \"size\": 0,\n",
      "      \"query\": {\n",
      "        \"bool\": {\n",
      "          \"filter\": {\n",
      "            \"range\": {\n",
      "              \"order_date\": {\n",
      "                \"gte\": \"now-7d/d\",\n",
      "                \"lte\": \"now/d\",\n",
      "                \"time_zone\": \"CET\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"aggs\": {\n",
      "        \"daily_spending\": {\n",
      "          \"date_histogram\": {\n",
      "            \"field\": \"order_date\",\n",
      "            \"fixed_interval\": \"1d\",\n",
      "            \"time_zone\": \"CET\"\n",
      "          },\n",
      "          \"aggs\": {\n",
      "            \"total_spending\": {\n",
      "              \"sum\": {\n",
      "                \"field\": \"taxful_total_price\"\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{'took': 2, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 1195, 'relation': 'eq'}, 'max_score': None, 'hits': []}, 'aggregations': {'daily_spending': {'buckets': [{'key_as_string': '2023-06-12T00:00:00.000+02:00', 'key': 1686520800000, 'doc_count': 144, 'total_spending': {'value': 10328.9140625}}, {'key_as_string': '2023-06-13T00:00:00.000+02:00', 'key': 1686607200000, 'doc_count': 147, 'total_spending': {'value': 10886.546875}}, {'key_as_string': '2023-06-14T00:00:00.000+02:00', 'key': 1686693600000, 'doc_count': 137, 'total_spending': {'value': 11008.984375}}, {'key_as_string': '2023-06-15T00:00:00.000+02:00', 'key': 1686780000000, 'doc_count': 166, 'total_spending': {'value': 13210.5390625}}, {'key_as_string': '2023-06-16T00:00:00.000+02:00', 'key': 1686866400000, 'doc_count': 143, 'total_spending': {'value': 10263.95703125}}, {'key_as_string': '2023-06-17T00:00:00.000+02:00', 'key': 1686952800000, 'doc_count': 155, 'total_spending': {'value': 11282.36328125}}, {'key_as_string': '2023-06-18T00:00:00.000+02:00', 'key': 1687039200000, 'doc_count': 157, 'total_spending': {'value': 11489.234375}}, {'key_as_string': '2023-06-19T00:00:00.000+02:00', 'key': 1687125600000, 'doc_count': 146, 'total_spending': {'value': 10682.828125}}]}}}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe daily spending in the ecommerce shop over the last week is increasing. Here are the daily spending values for the last 7 days:\n",
      "\n",
      "- June 12th: 10328.91\n",
      "- June 13th: 10886.55\n",
      "- June 14th: 11008.98\n",
      "- June 15th: 13210.54\n",
      "- June 16th: 10263.96\n",
      "- June 17th: 11282.36\n",
      "- June 18th: 11489.23\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"The daily spending in the ecommerce shop over the last week is increasing. Here are the daily spending values for the last 7 days:\\n\\n- June 12th: 10328.91\\n- June 13th: 10886.55\\n- June 14th: 11008.98\\n- June 15th: 13210.54\\n- June 16th: 10263.96\\n- June 17th: 11282.36\\n- June 18th: 11489.23\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The daily spending in the ecommerce shop over the last week is increasing. Here are the daily spending values for the last 7 days:\\n\\n- June 12th: 10328.91\\n- June 13th: 10886.55\\n- June 14th: 11008.98\\n- June 15th: 13210.54\\n- June 16th: 10263.96\\n- June 17th: 11282.36\\n- June 18th: 11489.23'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#agent_executor.run(\"Who bought the most in e-commerce shop?\")\n",
    "#agent_executor.run(\"What's the total revenue of my ecommerce shop?\")\n",
    "#agent_executor.run(\"Can you find any trace of an attack to my website in the logs?\")\n",
    "#agent_executor.run(\"What is the top product sold this week?\")\n",
    "\n",
    "#agent_executor.run(\"Flights to which destination city are the most delayed?\")\n",
    "#agent_executor.run(\"Which IP sent the most of the bytes?\")\n",
    "agent_executor.run(\"What's median spending in the last 7 days in my ecommerce shop?\")\n",
    "#agent_executor.run(\"What's total revenue of my shop in the last 7 days?\")\n",
    "#agent_executor.run(\"How daily spending is increasing in my ecommerce shop over the last week?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
